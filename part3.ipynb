{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import variableImageSize as vis\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32x32: Images torch.Size([3269, 1, 32, 32]), Labels torch.Size([3269])\n",
      "48x48: Images torch.Size([3381, 1, 48, 48]), Labels torch.Size([3381])\n",
      "64x64: Images torch.Size([3350, 1, 64, 64]), Labels torch.Size([3350])\n"
     ]
    }
   ],
   "source": [
    "# Path to dataset\n",
    "root_dir = \"./data/MNIST/mnist-varres/test/\"\n",
    "\n",
    "# Load images grouped by resolution\n",
    "tensor_32, tensor_48, tensor_64 = vis.load_images_by_resolution(root_dir)\n",
    "\n",
    "# Print the size of each group\n",
    "print(f\"32x32: Images {tensor_32[0].shape}, Labels {tensor_32[1].shape}\")\n",
    "print(f\"48x48: Images {tensor_48[0].shape}, Labels {tensor_48[1].shape}\")\n",
    "print(f\"64x64: Images {tensor_64[0].shape}, Labels {tensor_64[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariableInputNetwork(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (global_pool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "Output shape for 32x32 input: torch.Size([8, 10])\n",
      "Output shape for 48x48 input: torch.Size([8, 10])\n",
      "Output shape for 64x64 input: torch.Size([8, 10])\n"
     ]
    }
   ],
   "source": [
    "model = vis.VariableInputNetwork(num_classes=10, N=64, pooling_type='max')\n",
    "print(model)\n",
    "\n",
    "# Test with variable input sizes\n",
    "input_32 = torch.randn(8, 1, 32, 32)  # Batch of 8 images, resolution 32x32\n",
    "input_48 = torch.randn(8, 1, 48, 48)  # Batch of 8 images, resolution 48x48\n",
    "input_64 = torch.randn(8, 1, 64, 64)  # Batch of 8 images, resolution 64x64\n",
    "\n",
    "output_32 = model(input_32)  # Should output (8, 10)\n",
    "output_48 = model(input_48)  # Should output (8, 10)\n",
    "output_64 = model(input_64)  # Should output (8, 10)\n",
    "\n",
    "print(f\"Output shape for 32x32 input: {output_32.shape}\")\n",
    "print(f\"Output shape for 48x48 input: {output_48.shape}\")\n",
    "print(f\"Output shape for 64x64 input: {output_64.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'variableImageSize' has no attribute 'count_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mvis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount_parameters\u001b[49m(model))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'variableImageSize' has no attribute 'count_parameters'"
     ]
    }
   ],
   "source": [
    "print(vis.count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO TRAINING LOOP FOR THIS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fuckyou",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
