{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import variableImageSize as vis\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to dataset\n",
    "root_dir = \"./data/MNIST/mnist-varres/test/\"\n",
    "\n",
    "# Load images grouped by resolution\n",
    "tensors_32, tensors_48, tensors_64 = vis.load_images_by_resolution(root_dir)\n",
    "test_tensors_by_resolution = {\n",
    "    32: tensors_32,\n",
    "    48: tensors_48,\n",
    "    64: tensors_64,\n",
    "}\n",
    "root_dir = \"./data/MNIST/mnist-varres/train/\"\n",
    "tensors_32, tensors_48, tensors_64 = vis.load_images_by_resolution(root_dir)\n",
    "train_tensors_by_resolution = {\n",
    "    32: tensors_32,\n",
    "    48: tensors_48,\n",
    "    64: tensors_64,\n",
    "}\n",
    "# Print the size of each group\n",
    "# print(f\"32x32: Images {tensor_32[0].shape}, Labels {tensor_32[1].shape}\")\n",
    "# print(f\"48x48: Images {tensor_48[0].shape}, Labels {tensor_48[1].shape}\")\n",
    "# print(f\"64x64: Images {tensor_64[0].shape}, Labels {tensor_64[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariableInputNetwork(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 81, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (global_pool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=81, out_features=10, bias=True)\n",
      ")\n",
      "Output shape for 32x32 input: torch.Size([8, 10])\n",
      "Output shape for 48x48 input: torch.Size([8, 10])\n",
      "Output shape for 64x64 input: torch.Size([8, 10])\n"
     ]
    }
   ],
   "source": [
    "model = vis.VariableInputNetwork(num_classes=10, N=81, pooling_type='max')\n",
    "print(model)\n",
    "\n",
    "# Test with variable input sizes\n",
    "input_32 = torch.randn(8, 1, 32, 32)  # Batch of 8 images, resolution 32x32\n",
    "input_48 = torch.randn(8, 1, 48, 48)  # Batch of 8 images, resolution 48x48\n",
    "input_64 = torch.randn(8, 1, 64, 64)  # Batch of 8 images, resolution 64x64\n",
    "\n",
    "output_32 = model(input_32)  # Should output (8, 10)\n",
    "output_48 = model(input_48)  # Should output (8, 10)\n",
    "output_64 = model(input_64)  # Should output (8, 10)\n",
    "\n",
    "print(f\"Output shape for 32x32 input: {output_32.shape}\")\n",
    "print(f\"Output shape for 48x48 input: {output_48.shape}\")\n",
    "print(f\"Output shape for 64x64 input: {output_64.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29029\n"
     ]
    }
   ],
   "source": [
    "print(vis.count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with MAX pooling:\n",
      "Epoch 1/5\n",
      "Training on resolution 32x32:\n",
      "  Train Loss: 0.7848, Train Acc: 76.13%\n",
      "Training on resolution 48x48:\n",
      "  Train Loss: 0.1877, Train Acc: 94.49%\n",
      "Training on resolution 64x64:\n",
      "  Train Loss: 0.1434, Train Acc: 95.53%\n",
      "--------------------------------------------------\n",
      "Epoch 2/5\n",
      "Training on resolution 32x32:\n",
      "  Train Loss: 0.1203, Train Acc: 96.21%\n",
      "Training on resolution 48x48:\n",
      "  Train Loss: 0.0979, Train Acc: 97.06%\n",
      "Training on resolution 64x64:\n",
      "  Train Loss: 0.0854, Train Acc: 97.45%\n",
      "--------------------------------------------------\n",
      "Epoch 3/5\n",
      "Training on resolution 32x32:\n",
      "  Train Loss: 0.0826, Train Acc: 97.54%\n",
      "Training on resolution 48x48:\n",
      "  Train Loss: 0.0710, Train Acc: 97.69%\n",
      "Training on resolution 64x64:\n",
      "  Train Loss: 0.0665, Train Acc: 97.99%\n",
      "--------------------------------------------------\n",
      "Epoch 4/5\n",
      "Training on resolution 32x32:\n",
      "  Train Loss: 0.0686, Train Acc: 97.94%\n",
      "Training on resolution 48x48:\n",
      "  Train Loss: 0.0592, Train Acc: 98.20%\n",
      "Training on resolution 64x64:\n",
      "  Train Loss: 0.0570, Train Acc: 98.30%\n",
      "--------------------------------------------------\n",
      "Epoch 5/5\n",
      "Training on resolution 32x32:\n",
      "  Train Loss: 0.0569, Train Acc: 98.17%\n",
      "Training on resolution 48x48:\n",
      "  Train Loss: 0.0426, Train Acc: 98.66%\n",
      "Training on resolution 64x64:\n",
      "  Train Loss: 0.0489, Train Acc: 98.50%\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluating MAX pooling on test data:\n",
      "Resolution 32x32: Test Loss: 0.0560, Test Acc: 98.20%\n",
      "Resolution 48x48: Test Loss: 0.0457, Test Acc: 98.49%\n",
      "Resolution 64x64: Test Loss: 0.0423, Test Acc: 98.60%\n",
      "\n",
      "Training with AVG pooling:\n",
      "Epoch 1/5\n",
      "Training on resolution 32x32:\n",
      "  Train Loss: 1.5807, Train Acc: 45.35%\n",
      "Training on resolution 48x48:\n",
      "  Train Loss: 0.8807, Train Acc: 76.24%\n",
      "Training on resolution 64x64:\n",
      "  Train Loss: 0.6231, Train Acc: 83.62%\n",
      "--------------------------------------------------\n",
      "Epoch 2/5\n",
      "Training on resolution 32x32:\n",
      "  Train Loss: 0.4121, Train Acc: 89.23%\n",
      "Training on resolution 48x48:\n",
      "  Train Loss: 0.3244, Train Acc: 91.08%\n",
      "Training on resolution 64x64:\n",
      "  Train Loss: 0.3471, Train Acc: 91.26%\n",
      "--------------------------------------------------\n",
      "Epoch 3/5\n",
      "Training on resolution 32x32:\n",
      "  Train Loss: 0.3157, Train Acc: 92.44%\n",
      "Training on resolution 48x48:\n",
      "  Train Loss: 0.2280, Train Acc: 93.59%\n",
      "Training on resolution 64x64:\n",
      "  Train Loss: 0.2577, Train Acc: 93.69%\n",
      "--------------------------------------------------\n",
      "Epoch 4/5\n",
      "Training on resolution 32x32:\n",
      "  Train Loss: 0.2703, Train Acc: 93.58%\n",
      "Training on resolution 48x48:\n",
      "  Train Loss: 0.1818, Train Acc: 94.90%\n",
      "Training on resolution 64x64:\n",
      "  Train Loss: 0.2135, Train Acc: 94.67%\n",
      "--------------------------------------------------\n",
      "Epoch 5/5\n",
      "Training on resolution 32x32:\n",
      "  Train Loss: 0.2310, Train Acc: 94.68%\n",
      "Training on resolution 48x48:\n",
      "  Train Loss: 0.1515, Train Acc: 95.67%\n",
      "Training on resolution 64x64:\n",
      "  Train Loss: 0.1815, Train Acc: 95.48%\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluating AVG pooling on test data:\n",
      "Resolution 32x32: Test Loss: 0.2307, Test Acc: 96.15%\n",
      "Resolution 48x48: Test Loss: 0.1385, Test Acc: 95.95%\n",
      "Resolution 64x64: Test Loss: 0.1437, Test Acc: 96.15%\n",
      "\n",
      "Comparison of Pooling Methods:\n",
      "\n",
      "MAX Pooling:\n",
      "Resolution 32x32: Test Loss = 0.0560, Test Acc = 98.20%\n",
      "Resolution 48x48: Test Loss = 0.0457, Test Acc = 98.49%\n",
      "Resolution 64x64: Test Loss = 0.0423, Test Acc = 98.60%\n",
      "\n",
      "AVG Pooling:\n",
      "Resolution 32x32: Test Loss = 0.2307, Test Acc = 96.15%\n",
      "Resolution 48x48: Test Loss = 0.1385, Test Acc = 95.95%\n",
      "Resolution 64x64: Test Loss = 0.1437, Test Acc = 96.15%\n"
     ]
    }
   ],
   "source": [
    "results = vis.train_and_compare_pooling(train_tensors_by_resolution, test_tensors_by_resolution, num_epochs=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fuckyou",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
